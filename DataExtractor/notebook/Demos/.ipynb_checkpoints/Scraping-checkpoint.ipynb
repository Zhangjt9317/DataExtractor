{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Documents From Websites\n",
    "\n",
    "### Methods:\n",
    "\n",
    "Scientific articles used in this work are journal publications published by Springer, Wiley, Elsevier, the Royal Society of Chemistry, and the Electrochemical Society from which we received permissions to download large amount of articles. For each publisher, we manually identified all material science related journals available for download. A web scraping engine was built using scrapy. Only full-text articles publihsed after 2000 were downloaded, including metadata such as journal name, article title, article abstract, authors, etc. \n",
    "\n",
    "All data were stored in a document-oriented database implemented using a MongoDB database instance. Becasue downloaded articles are in HTML/XML format, which contains irrelevant markups and stylesheets, we developed a customized library for parsing article markup strings into text paragraphs while keeping the structures of paper and sections headings. The current snapshot of the database contains XXX papers, from which we used XXX paragraphs in the experimental sections of each paper to conduct this research. The experimental sections were identified by using case-insensitive keyword matching in section headings. keywords like \"experiment\", \"synthesis\", and their morphological derivations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import re\n",
    "import urllib\n",
    "import time\n",
    "# import feedparser\n",
    "\n",
    "# import chemdataextractor\n",
    "# from chemdataextractor import Document\n",
    "# from chemdataextractor.reader import NlmXmlReader\n",
    "# from chemdataextractor.reader import XmlReader\n",
    "# from chemdataextractor.reader import PlainTextReader\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "els_key = \"4bc84cbdadca6050062348015ac963aa\"\n",
    "sn_key = \"eca22bc7a0b1ee3153ab02c024a6a06e\"\n",
    "folder = \"testing_download_articles/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search API\n",
    "\n",
    "In all platforms, we need to first search articles by topics of interst and then retrieve the full text using another API. Refer to https://dev.elsevier.com/documentation/FullTextRetrievalAPI.wadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arx_scrape(search_term, start_idx, scope='ti'):\n",
    "    '''uses urllib, time, and feedparser'''\n",
    "    #first escape search terms\n",
    "    search_term= search_term.replace('\"',\"%22\").replace(\" \", \"+\");\n",
    "    # set wait time and iteration step\n",
    "    iterstep= 200;\n",
    "    wait_time= 2 \n",
    "    base_url = 'http://export.arxiv.org/api/query?'\n",
    "    start= start_idx\n",
    "    date_dict={\n",
    "        \"date\":[],\n",
    "        \"article_id\": [],\n",
    "        \"summary\":[],\n",
    "        \"source\": \"arXiv\"\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        response= urllib.request.urlopen(els_base_url+f\"search_query={scope}:{search_term}&sortBy=submittedDate&sortOrder=ascending&start={start}&max_results={iterstep}\")\n",
    "        feed= feedparser.parse(response)\n",
    "        if not feed.entries:\n",
    "            print('query complete')\n",
    "            print(f\"There should be {feed.feed.opensearch_totalresults} results?\")\n",
    "            break\n",
    "        date_dict['date'].extend([entry.published for entry in feed.entries])\n",
    "        date_dict['article_id'].extend([entry.id.split('/abs/')[-1] for entry in feed.entries])\n",
    "        date_dict['summary'].extend([entry.summary.replace(\"\\n\", \" \") for entry in feed.entries])\n",
    "        print(f\"gathering results {start} to {start + iterstep-1} \")\n",
    "        start = start + iterstep\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "    return pd.DataFrame(date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #collect all all:organic photovoltaics from arXiv\n",
    "# a1 = arx_scrape(\"all\", 0, scope='organic photovoltaics OR organic solar cell')\n",
    "# a2 = arx_scrape(\"all\", 10000, scope='organic photovoltaics OR organic solar cell')\n",
    "# a3 = arx_scrape(\"all\", 12200, scope='organic photovoltaics OR organic solar cell')\n",
    "# a4 = arx_scrape(\"all\", 14400, scope='organic photovoltaics OR organic solar cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_a = pd.concat([a1, a2, a3, a4], ignore_index=True)\n",
    "# all_a.head()\n",
    "# all_a['date']= pd.DatetimeIndex(all_ai['date']).normalize()\n",
    "# all_a.to_csv('./els.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv('./arxiv_physics.chem_ph.csv')\n",
    "# corpus = a['summary']\n",
    "# corpus = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the arXiv we have scraped 14800 abstracts,date and article ID for them. Usually abstracts contain the most concise information for the entire paper. Thus focusing on property extraction from abstracts is the main trend.\n",
    "\n",
    "The followings are elsvier and springer nature's api keys. In order to design a useful scraper, we beed to desgin multiple layers of filtering mechanism in order to scrape the right articles. For example, only \"organic photovoltaics\" or \"peroskite solar cell\" can also be broad. More details can be added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Text Retrieval API\n",
    "\n",
    "This section use the full text retrieval API to retrieve full-article information and save it to either database (production) or local folders (development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "folder = \"testing_download_articles\"\n",
    "# count is 10 so we output 10 results\n",
    "els_url = \"https://api.elsevier.com/content/search/scopus?query=organic%26photovoltaics&count=100&start=1&apiKey=4bc84cbdadca6050062348015ac963aa\"\n",
    "r = requests.get(els_url)\n",
    "\n",
    "with open(folder + '/write_test_els_paper2.json', 'wb') as file:\n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'service-error': {'status': {'statusCode': 'INVALID_INPUT',\n",
      "                              'statusText': 'Exceeds the maximum number '\n",
      "                                            'allowed for the service level'}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "file = \"testing_download_articles/write_test_els_paper2.json\"\n",
    "\n",
    "with open('testing_download_articles/write_test_els_paper2.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1038/s42004-020-0256-7', '10.1038/s41467-020-15215-x', '10.1038/s41467-020-15078-2', '10.1038/s41598-020-61768-8', '10.1038/s41467-019-13909-5', '10.1007/s12034-019-2020-0', '10.1038/s41598-020-58310-1', '10.1038/s41598-020-61282-x', '10.1038/s41467-019-13437-2', '10.1038/s41467-020-14401-1', '10.1038/s42005-020-0313-7', '10.1007/s12034-019-2002-2', '10.1038/s41598-020-61602-1', '10.1038/s41467-020-14986-7', '10.1038/s41467-020-14661-x', '10.1038/s41427-020-0202-2', '10.1038/s41427-020-0198-7', '10.1038/s41467-019-14237-4', '10.1038/s41467-019-13908-6', '10.1038/s41377-020-0264-5']\n",
      "['Mapping the optoelectronic property space of small aromatic molecules', 'Molecular vibrations reduce the maximum achievable photovoltage in organic solar cells', 'Ultra-high open-circuit voltage of tin perovskite solar cells via an electron transporting layer design', 'Origin of Rashba Spin-Orbit Coupling in 2D and 3D Lead Iodide Perovskites', 'Highly efficient all-inorganic perovskite solar cells with suppressed non-radiative recombination by a Lewis base', 'Time-resolved fluorescence decay and Gaussian analysis of P3HT-derived Ho <sup>3 +</sup> - and Tm <sup>3 +</sup> -doped ZnO nanostructures', 'Zinc phthalocyanines as light harvesters for SnO<inf>2</inf>-based solar cells: a case study', 'Conjugated Polymer Controlled Morphology and Charge Transport of Small-Molecule Organic Semiconductors', 'Cascade surface modification of colloidal quantum dot inks enables efficient bulk homojunction photovoltaics', 'The role of photon recycling in perovskite light-emitting diodes', 'Direct evidence of weakly dispersed and strongly anharmonic optical phonons in hybrid perovskites', 'Effect of tertiary butylpyridine in stability of methylammonium lead iodide perovskite thin films', 'Synergistic enhancement in the microelectronic properties of poly-(dioctylfluorene) based Schottky devices by CdSe quantum dots', 'Directed self-assembly of viologen-based 2D semiconductors with intrinsic UVâ€“SWIR photoresponse after photo/thermo activation', 'Edge-driven nanomembrane-based vertical organic transistors showing a multi-sensing capability', 'Quasi-2D halide perovskites for resistive switching devices with ON/OFF ratios above 10<sup>9</sup>', 'Selective growth of Î±-form zinc phthalocyanine nanowire crystals via the flow rate control of physical vapor transport', 'Efficient electron transmission in covalent organic framework nanosheets for highly active electrocatalytic carbon dioxide reduction', 'Sub-1.4eV bandgap inorganic perovskite solar cells with long-term stability', 'Ultrafast and broadband photodetectors based on a perovskite/organic bulk heterojunction for large-dynamic-range imaging']\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "ls2 = []\n",
    "for i in data['search-results']['entry']:\n",
    "    # print(i)\n",
    "    if 'prism:doi' in i:\n",
    "        # print(i['prism:doi'])\n",
    "        ls.append(i['prism:doi'])\n",
    "        ls2.append(i['dc:title'])\n",
    "print(ls)\n",
    "print(ls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_articles(file):\n",
    "    \"\"\"\n",
    "    This is the combination of search and full text retrieval API\n",
    "    input : JSON file location\n",
    "    \n",
    "    \"\"\"\n",
    "    names = []\n",
    "    dois = []\n",
    "    \n",
    "    # read json as dictionary in python\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for i in data['search-results']['entry']:\n",
    "        if 'prism:doi' in i:\n",
    "            dois.append(i['prism:doi'])\n",
    "            names.append(i['dc:title'])\n",
    "    return dois, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['10.1016/j.cej.2019.122813',\n",
       "  '10.1016/j.jhazmat.2019.121260',\n",
       "  '10.1016/j.jhazmat.2019.121275',\n",
       "  '10.1016/j.cej.2019.122464',\n",
       "  '10.1016/j.amc.2019.124780',\n",
       "  '10.1016/j.renene.2019.07.038',\n",
       "  '10.1016/j.renene.2019.07.018',\n",
       "  '10.1016/j.dyepig.2019.107927',\n",
       "  '10.1016/j.dyepig.2019.107925',\n",
       "  '10.1016/j.renene.2019.08.070',\n",
       "  '10.1016/j.dyepig.2019.107890',\n",
       "  '10.1016/j.dyepig.2019.107887',\n",
       "  '10.1016/j.renene.2019.07.028',\n",
       "  '10.1016/j.dyepig.2019.107891',\n",
       "  '10.1016/j.jechem.2019.04.019',\n",
       "  '10.1016/j.dyepig.2019.107840',\n",
       "  '10.1016/j.dyepig.2019.107880',\n",
       "  '10.1016/j.renene.2019.08.094',\n",
       "  '10.1016/j.dyepig.2019.107921',\n",
       "  '10.1016/j.dyepig.2019.107881'],\n",
       " ['The flexible-transparent p-n junction film device of N-doped Cu<inf>2</inf>O/SnO<inf>2</inf> orderly nanowire arrays towards highly photovoltaic conversion and stability',\n",
       "  'Improving the flame retardancy of poly(lactic acid) using an efficient ternary hybrid flame retardant by dual modification of graphene oxide with phenylphosphinic acid and nano MOFs',\n",
       "  'Enhanced visible light photocatalytic activity of g-C<inf>3</inf>N<inf>4</inf> decorated ZrO<inf>2-x</inf> nanotubes heterostructure for degradation of tetracycline hydrochloride',\n",
       "  'Nitrogen-rich carbon-supported ultrafine MoC nanoparticles for the hydrotreatment of oleic acid into diesel-like hydrocarbons',\n",
       "  'Analytic network process: An overview of applications',\n",
       "  'The controllable deposÄ±tÄ±on of large area roll-to-roll sputtered ito thÄ±n fÄ±lms for photovoltaÄ±c applÄ±catÄ±ons',\n",
       "  'Embedded BIPV module-level DC/DC converters: Classification of optimal ratings',\n",
       "  'Effect of interface modification in polymer solar cells: An in-depth investigation of the structural variation of organic dye for interlayer material',\n",
       "  'Synergistic interactions between N3 dye and perovskite CH<inf>3</inf>NH<inf>3</inf>PbI<inf>3</inf> for aqueous-based photoresponsiveness under visible light',\n",
       "  'An explicit method to extract fitting parameters in lumped-parameter equivalent circuit model of industrial solar cells',\n",
       "  'A mild and sequentially Pd/Cu-catalyzed domino synthesis of acidochromic Indolo[3,2-a]carbazoles â€“ Free bases of apocyanine dyes',\n",
       "  '2,3-di(2-furyl) quinoxaline bearing 3 -ethyl rhodanine and 1,3 indandione based heteroaromatic conjugated T-shaped push -pull chromophores: Design, synthesis, photophysical and non-linear optical investigations',\n",
       "  'Levelized energy and exergy costings per life cycle assessment of a combined cooling, heating, power and tourism system of the San Kamphaeng hot spring, Thailand',\n",
       "  'An insight into the effect of S,S-dioxided thiophene on the opto-physical/electro-chemical properties and light stability for indophenine derivatives',\n",
       "  'Improved perovskite solar cell efficiency by tuning the colloidal size and free ion concentration in precursor solution using formic acid additive',\n",
       "  'Blue-colored dyes featuring a diketopyrrolopyrrole spacer for translucent dye-sensitized solar cells',\n",
       "  'A triarylamine-based fluorescent covalent organic framework for efficient detection and removal of Mercury(II) ion',\n",
       "  'Sustainable development using renewable energy technology',\n",
       "  'Novel triphenylamine polyazomethines bearing carbazole and trifluoromethyl substituents: Preparation and electrochromic behavior',\n",
       "  'New pyrene-based butterfly-shaped blue AIEgens: Synthesis, structure, aggregation-induced emission and their nondoped blue OLEDs'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"testing_download_articles/write_test_els_paper2.json\"\n",
    "\n",
    "search_articles(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Them Together\n",
    "\n",
    "In this case we can combine both of them together to get a better view on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull articles\n",
    "count = 0\n",
    "for i in ls:\n",
    "    els_url = 'https://api.elsevier.com/content/abstract/doi/' + i + '?APIKey=' + els_key\n",
    "    r = requests.get(els_url)\n",
    "    for num in range(len(ls)):\n",
    "        with open(folder + f'/abstract{num}.xml', 'wb') as file:\n",
    "            file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_and_pull:\n",
    "    def __init__(self):\n",
    "        self.els_key = \"4bc84cbdadca6050062348015ac963aa\"\n",
    "        self.file = \"testing_download_articles/write_test_els_paper2.json\"\n",
    "        self.folder = \"testing_download_articles/\"\n",
    "        \n",
    "    def search_articles(self,file):\n",
    "        \"\"\"\n",
    "        This is the combination of search and full text retrieval API\n",
    "        input : JSON file location\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        dois = []\n",
    "\n",
    "        # read json as dictionary in python\n",
    "        file = self.file\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for i in data['search-results']['entry']:\n",
    "            if 'prism:doi' in i:\n",
    "                dois.append(i['prism:doi'])\n",
    "                names.append(i['dc:title'])\n",
    "        return dois\n",
    "\n",
    "    def pull_articles(self,ls):\n",
    "        \"\"\"\n",
    "        This function writes txt files for scraped documents\n",
    "        \"\"\"\n",
    "        # pull articles\n",
    "        doi = self.search_articles(file)\n",
    "        els_key = self.els_key\n",
    "        \n",
    "        for i in doi:\n",
    "            els_url = 'https://api.elsevier.com/content/article/doi/' + doi + '?APIKey=' + els_key\n",
    "            r = requests.get(els_url)\n",
    "            for num in range(len(ls)):\n",
    "                with open(folder + f'/write_test_els_paper{num}.xml', 'wb') as file:\n",
    "                    file.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under school's network this combination of APIs work since UW is a subscriber. Next we are going to customize the parser to make it automated and more powerful\n",
    "\n",
    "The followings are some platforms we can access to:\n",
    "1. Elsevier\n",
    "2. Springer\n",
    "3. ACS\n",
    "4. RSC\n",
    "\n",
    "They are all major publishers for main journals in OPV and other fields of study. In this case we only need these four.\n",
    "\n",
    "Mongodb is a NoSQL database that can is document-oriented. It is perfect to store search results. The tabulated data can either be directly output or stored in a SQL database like MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
